{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading data from\n",
    "https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
    "57026/57026 \\[==============================\\] - 0s 0us/step\n",
    "\n",
    "(((404, 13), numpy.ndarray), ((102, 13), numpy.ndarray), ((404,),\n",
    "numpy.ndarray), ((102,), numpy.ndarray))\n",
    "\n",
    "01234567891011120\n",
    "0.091780.04.050.00.5106.41684.12.64635.0296.016.6395.509.041\n",
    "0.0564440.06.411.00.4476.75832.94.07764.0254.017.6396.903.532\n",
    "0.105740.027.740.00.6095.98398.81.86814.0711.020.1390.1118.073\n",
    "0.091640.010.810.00.4136.0657.85.28734.0305.019.2390.915.524\n",
    "5.090170.018.100.00.7136.29791.82.368224.0666.020.2385.0917.275\n",
    "0.101530.012.830.00.4376.27974.54.05225.0398.018.7373.6611.976\n",
    "0.318270.09.900.00.5445.91483.23.99864.0304.018.4390.7018.337\n",
    "0.290900.021.890.00.6246.17493.61.61194.0437.021.2388.0824.168\n",
    "4.038410.018.100.00.5326.22990.73.099324.0666.020.2395.3312.879\n",
    "0.224380.09.690.00.5856.02779.72.49826.0391.019.2396.9014.33 \\<class\n",
    "‘pandas.core.frame.DataFrame’\\> RangeIndex: 404 entries, 0 to 403 Data\n",
    "columns (total 13 columns): #ColumnNon-Null CountDtype00404 non-null\n",
    "float6411404 non-nullfloat6422404 non-nullfloat6433404\n",
    "non-nullfloat6444404 non-nullfloat6455404 non-nullfloat6466404\n",
    "non-nullfloat6477404 non-nullfloat6488404 non-nullfloat6499404\n",
    "non-nullfloat641010404 non-nullfloat641111404 non-nullfloat64 12 12 404\n",
    "non-null float64 dtypes: float64(13) memory usage: 41.2 KB\n",
    "\n",
    "\\<class ‘pandas.core.frame.DataFrame’\\> RangeIndex: 404 entries, 0 to\n",
    "403 Data columns (total 1 columns): \\# Column Non-Null Count Dtype\n",
    "\n",
    "0 0 404 non-null float64 dtypes: float64(1) memory usage: 3.3 KB\n",
    "\n",
    "012345678910count404.000000404.000000404.000000404.000000404.000000404.000000404.000000404.000000404.000000404.000000404.000000mean3.78998911.56806911.2140590.0693070.5545246.28482469.1193073.7922589.660891408.96039618.481931std9.13276124.2696486.9254620.2542900.1164080.72375928.0346062.1426518.736073169.6851662.157322min0.0063200.0000000.4600000.0000000.3850003.5610002.9000001.1370001.000000187.00000012.60000025%0.0819600.0000005.1900000.0000000.4520005.87875045.4750002.0970504.000000281.00000017.40000050%0.2626600.0000009.6900000.0000000.5380006.21000077.5000003.1675005.000000330.00000019.10000075%3.71787512.50000018.1000000.0000000.6240006.62050094.4250005.11800024.000000666.00000020.200000max88.976200100.00000027.7400001.0000000.8710008.780000100.00000012.12650024.000000711.00000022.000000\n",
    "\n",
    "# Create column transformer ct = make_column_transformer(\n",
    "\n",
    "(MinMaxScaler(), \\[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12\\]) )\n",
    "\n",
    "# Normalization and data type change\n",
    "\n",
    "X_train = ct.fit_transform(X_train).astype(‘float32’) X_test =\n",
    "ct.transform(X_test).astype(‘float32’) y_train =\n",
    "y_train.astype(‘float32’) y_test = y_test.astype(‘float32’)\n",
    "\n",
    "# Distribution of X_train feature values after normalization pd.DataFrame(X_train).describe()\n",
    "\n",
    "0 1 2 3 4 5 6 7 8 9\n",
    "10count404.000000404.000000404.000000404.000000404.000000404.000000404.000000404.000000404.000000404.000000404.000000mean0.0425280.1156810.3942100.3488150.5219050.6819700.2416180.3765600.4235890.6257370.897607std0.1026500.2426960.2538660.2395220.1386780.2887190.1949730.3798290.3238270.2295020.232131min0.0000000.0000000.0000000.0000000.0000000.0000000.0000000.0000000.0000000.0000000.00000025%0.0008500.0000000.1733870.1378600.4440980.4384660.0873610.1304350.1793890.5106380.94499250%0.0028810.0000000.3383430.3148150.5075690.7682800.1847670.1739130.2729010.6914890.98589275%0.0417170.1250000.6466280.4917700.5862230.9425850.3622551.0000000.9141220.8085110.997252max1.0000001.0000001.0000001.0000001.0000001.0000001.0000001.0000001.0000001.0000001.000000\n",
    "\n",
    "# Reserve data for validation\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "test_size=0.1, random_state=42) X_train.shape, X_val.shape,\n",
    "y_train.shape, y_val.shape((363, 12), (41, 12), (363,), (41,))\n",
    "\n",
    "# Set random seed tf.random.set_seed(42)\n",
    "\n",
    "# Building the model\n",
    "\n",
    "model = tf.keras.Sequential(\\[ tf.keras.layers.Dense(units=10,\n",
    "activation=‘relu’, input_shape=(X_train.shape\\[1\\],), name=‘Dense_1’),\n",
    "tf.keras.layers.Dense(units=100, activation=‘relu’, name=‘Dense_2’),\n",
    "tf.keras.layers.Dense(units=1, name=‘Prediction’)\\])\n",
    "\n",
    "# Compiling the model model.compile(\n",
    "\n",
    "loss = tf.keras.losses.mean_squared_error, optimizer =\n",
    "tf.keras.optimizers.RMSprop(learning_rate=0.01), metrics = \\[‘mse’\\] )\n",
    "\n",
    "# Training the model history = model.fit(\n",
    "\n",
    "X_train, y_train, batch_size=32, epochs=50, validation_data=(X_val,\n",
    "y_val) )\n",
    "\n",
    "Epoch 1/50 12/12 \\[==============================\\] - 1s 33ms/step -\n",
    "loss: 308.4484 - mse: 308.4484 - val_loss: 146.9222 - val_mse: 146.9222\n",
    "Epoch 2/50 12/12 \\[==============================\\] - 0s 9ms/step -\n",
    "loss: 95.1682 - mse: 95.1682 - val_loss: 92.9939 - val_mse: 92.9939\n",
    "Epoch 3/50 12/12 \\[==============================\\] - 0s 7ms/step -\n",
    "loss: 62.2104 - mse: 62.2104 - val_loss: 68.8015 - val_mse: 68.8015\n",
    "Epoch 4/50 12/12 \\[==============================\\] - 0s 8ms/step -\n",
    "loss: 49.0687 - mse: 49.0687 - val_loss: 56.8894 - val_mse: 56.8894\n",
    "Epoch 5/50 12/12 \\[==============================\\] - 0s 8ms/step -\n",
    "loss: 45.6809 - mse: 45.6809 - val_loss: 68.7085 - val_mse: 68.7085\n",
    "Epoch 6/50 12/12 \\[==============================\\] - 0s 7ms/step -\n",
    "loss: 38.9542 - mse: 38.9542 - val_loss: 61.3664 - val_mse: 61.3664\n",
    "Epoch 7/50 12/12 \\[==============================\\] - 0s 9ms/step -\n",
    "loss: 32.9990 - mse: 32.9990 - val_loss: 35.6852 - val_mse: 35.6852\n",
    "Epoch 8/50 12/12 \\[==============================\\] - 0s 10ms/step -\n",
    "loss: 29.6053 - mse: 29.6053 - val_loss: 47.0410 - val_mse: 47.0410\n",
    "Epoch 9/50 12/12 \\[==============================\\] - 0s 8ms/step -\n",
    "loss: 28.8039 - mse: 28.8039 - val_loss: 30.4692 - val_mse: 30.4692\n",
    "Epoch 10/50 12/12 \\[==============================\\] - 0s 8ms/step -\n",
    "loss: 28.7124 - mse: 28.7124 - val_loss: 38.0187 - val_mse: 38.0187\n",
    "Epoch 11/50 12/12 \\[==============================\\] - 0s 5ms/step -\n",
    "loss: 23.2083 - mse: 23.2083 - val_loss: 45.0314 - val_mse: 45.0314\n",
    "Epoch 12/50 12/12 \\[==============================\\] - 0s 5ms/step -\n",
    "loss: 26.8295 - mse: 26.8295 - val_loss: 25.9321 - val_mse: 25.9321\n",
    "Epoch 13/50 12/12 \\[==============================\\] - 0s 5ms/step -\n",
    "loss: 22.4063 - mse: 22.4063 - val_loss: 33.7716 - val_mse: 33.7716\n",
    "Epoch 14/50 12/12 \\[==============================\\] - 0s 5ms/step -\n",
    "loss: 23.0061 - mse: 23.0061 - val_loss: 19.8987 - val_mse: 19.8987\n",
    "Epoch 15/50 12/12 \\[==============================\\] - 0s 6ms/step -\n",
    "loss: 22.7476 - mse: 22.7476 - val_loss: 19.6241 - val_mse: 19.6241\n",
    "Epoch 16/50 12/12 \\[==============================\\] - 0s 5ms/step -\n",
    "loss: 21.5558 - mse: 21.5558 - val_loss: 22.3366 - val_mse: 22.3366\n",
    "Epoch 17/50 12/12 \\[==============================\\] - 0s 6ms/step -\n",
    "loss: 22.3931 - mse: 22.3931 - val_loss: 46.4523 - val_mse: 46.4523\n",
    "Epoch 18/50 12/12 \\[==============================\\] - 0s 7ms/step -\n",
    "loss: 23.5593 - mse: 23.5593 - val_loss: 18.2555 - val_mse: 18.2555\n",
    "Epoch 19/50 12/12 \\[==============================\\] - 0s 7ms/step -\n",
    "loss: 19.2828 - mse: 19.2828 - val_loss: 17.9827 - val_mse: 17.9827\n",
    "Epoch 20/50 12/12 \\[==============================\\] - 0s 5ms/step -\n",
    "loss: 22.7105 - mse: 22.7105 - val_loss: 20.5292 - val_mse: 20.5292\n",
    "Epoch 21/50 12/12 \\[==============================\\] - 0s 7ms/step -\n",
    "loss: 22.5749 - mse: 22.5749 - val_loss: 18.6884 - val_mse: 18.6884\n",
    "Epoch 22/50 12/12 \\[==============================\\] - 0s 5ms/step -\n",
    "loss: 19.0899 - mse: 19.0899 - val_loss: 58.9656 - val_mse: 58.9656\n",
    "Epoch 23/50 12/12 \\[==============================\\] - 0s 6ms/step -\n",
    "loss: 22.1505 - mse: 22.1505 - val_loss: 17.7170 - val_mse: 17.7170\n",
    "Epoch 24/50 12/12 \\[==============================\\] - 0s 5ms/step -\n",
    "loss: 21.5239 - mse: 21.5239 - val_loss: 17.5552 - val_mse: 17.5552\n",
    "Epoch 25/50 12/12 \\[==============================\\] - 0s 5ms/step -\n",
    "loss: 18.7696 - mse: 18.7696 - val_loss: 33.4806 - val_mse: 33.4806\n",
    "Epoch 26/50 12/12 \\[==============================\\] - 0s 5ms/step -\n",
    "loss: 21.0288 - mse: 21.0288 - val_loss: 37.7337 - val_mse: 37.7337\n",
    "Epoch 27/50 12/12 \\[==============================\\] - 0s 5ms/step -\n",
    "loss: 19.4240 - mse: 19.4240 - val_loss: 27.9656 - val_mse: 27.9656\n",
    "Epoch 28/50 12/12 \\[==============================\\] - 0s 7ms/step -\n",
    "loss: 18.7796 - mse: 18.7796 - val_loss: 16.4296 - val_mse: 16.4296\n",
    "Epoch 29/50 12/12 \\[==============================\\] - 0s 6ms/step -\n",
    "loss: 19.5165 - mse: 19.5165 - val_loss: 36.3188 - val_mse: 36.3188\n",
    "\n",
    "(22.235537, 24.89756)\n",
    "\n",
    "Evaluation on Test data\n",
    "\n",
    "4/4 \\[==============================\\] - 0s 4ms/step - loss: 18.0088 -\n",
    "mse: 18.0088\n",
    "\n",
    "Model loss on test set: 18.00882339477539 Model mean squared error on\n",
    "test set: 18.01\n",
    "\n",
    "4/4 \\[==============================\\] - 0s 4ms/step\n",
    "array(\\[19.403996\\], dtype=float32)"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
